# -*- coding: utf-8 -*-
"""Model_Predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xtPcNMYVUWffqApgpEe12e7uxCxsCvQh

This is the file which predicts sentiment using the model and the texts passed in.

First function. Don't call this function from outside this file. The Model class will call it to clean up the texts passed in.
"""

def clean_text(line):
      
  import re
  
  from nltk.stem import WordNetLemmatizer
  from nltk.tokenize import word_tokenize

  # Defining dictionary containing all emojis with their meanings.
  emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', 
          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',
          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\': 'annoyed', 
          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',
          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',
          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', ":'-)": 'sadsmile', ';)': 'wink', 
          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}

  ## Defining set containing all stopwords in english.
  stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',
            'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',
            'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',
            'does', 'doing', 'down', 'during', 'each','few', 'for', 'from', 
            'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',
            'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',
            'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',
            'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',
            'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're',
            's', 'same', 'she', "shes", 'should', "shouldve",'so', 'some', 'such',
            't', 'than', 'that', "thatll", 'the', 'their', 'theirs', 'them',
            'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 
            'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',
            'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',
            'why', 'will', 'with', 'won', 'y', 'you', "youd","youll", "youre",
            "youve", 'your', 'yours', 'yourself', 'yourselves']

  line = str.lower(line)

  link_regex = r'(http://[^ ]*|https://[^ ]*|www\.[^ ]*)'
  user_regex = r'@[^ ]*'
  repeat_regex = r'(.)\1\1+'
  repeat_replace_regex = r'\1\1'

  not_alpha_regex = r'[^a-zA-z0-9]'

  line = re.sub(link_regex, 'URL', line)

  for emoji in emojis:
    line = line.replace(emoji, ' EMOJI' + emojis[emoji] + ' ')

  line = re.sub(user_regex, 'USER', line)
  line = re.sub(repeat_regex, repeat_replace_regex, line)
  line = re.sub(not_alpha_regex, ' ', line)

  lemmatizer = WordNetLemmatizer()
  cleaned_line = ''

  for token in word_tokenize(line):
    if not token in stopwordlist:

      if len(token) > 1:
        cleaned_line += (lemmatizer.lemmatize(token) + ' ')

  return cleaned_line

"""This function converts a line into an array of numerical tokens to be passed into the model, because it only works with numbers. Don't call from outside this file."""

def tokenize_sentence(X, tokenizer):
  from tensorflow.keras.preprocessing.sequence import pad_sequences
  
  tokenizer.fit_on_texts(X)
  X_padded = pad_sequences(tokenizer.texts_to_sequences(X), padding = 'post', maxlen = 300)

  return X_padded

"""This function just downloads a few things. Don't call this either because this is called when an instance of the Model class is made."""

def download():
  import nltk

  nltk.download('punkt')
  nltk.download('wordnet')

"""The Model class. Consists of a Constructor and 2 methods. Constructor imports a few things and loads the model from the directory given and also sets up the Tokenizer(which is needed for the tokenize function). The predict() method does the predicting part and the predict_sentiment() method takes in data from the API and calls the predict() method, returning the value returned from predict()."""

class Model:
  
  def __init__(self, model_link):
    import tensorflow as tf
    from tensorflow.keras.preprocessing.text import Tokenizer

    download()
    
    self.model = tf.keras.models.load_model(model_link)
    self.tokenizer = Tokenizer(num_words = 100, oov_token='<oov>')
    
  def predict(self, texts):
    import numpy as np

    texts = [clean_text(text) for text in texts]
    predictions = np.round(self.model.predict(tokenize_sentence(texts, self.tokenizer)))

    return np.round(np.mean(predictions))

  #def predict_sentiment(self, json_data):